{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(759807, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>start station name</th>\n",
       "      <th>start station latitude</th>\n",
       "      <th>start station longitude</th>\n",
       "      <th>end station name</th>\n",
       "      <th>end station latitude</th>\n",
       "      <th>end station longitude</th>\n",
       "      <th>usertype</th>\n",
       "      <th>birth year</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142</td>\n",
       "      <td>2019-02-01 15:35:02.0820</td>\n",
       "      <td>2019-02-01 15:37:24.1360</td>\n",
       "      <td>Exchange Place</td>\n",
       "      <td>40.716247</td>\n",
       "      <td>-74.033459</td>\n",
       "      <td>Harborside</td>\n",
       "      <td>40.719252</td>\n",
       "      <td>-74.034234</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>223</td>\n",
       "      <td>2019-02-01 17:00:46.8900</td>\n",
       "      <td>2019-02-01 17:04:30.5500</td>\n",
       "      <td>Exchange Place</td>\n",
       "      <td>40.716247</td>\n",
       "      <td>-74.033459</td>\n",
       "      <td>Grand St</td>\n",
       "      <td>40.715178</td>\n",
       "      <td>-74.037683</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106</td>\n",
       "      <td>2019-02-01 17:08:01.3260</td>\n",
       "      <td>2019-02-01 17:09:47.4400</td>\n",
       "      <td>Exchange Place</td>\n",
       "      <td>40.716247</td>\n",
       "      <td>-74.033459</td>\n",
       "      <td>Paulus Hook</td>\n",
       "      <td>40.714145</td>\n",
       "      <td>-74.033552</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>370</td>\n",
       "      <td>2019-02-01 17:09:31.2100</td>\n",
       "      <td>2019-02-01 17:15:41.6550</td>\n",
       "      <td>Exchange Place</td>\n",
       "      <td>40.716247</td>\n",
       "      <td>-74.033459</td>\n",
       "      <td>Newark Ave</td>\n",
       "      <td>40.721525</td>\n",
       "      <td>-74.046305</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>315</td>\n",
       "      <td>2019-02-01 17:19:53.2490</td>\n",
       "      <td>2019-02-01 17:25:09.1400</td>\n",
       "      <td>Exchange Place</td>\n",
       "      <td>40.716247</td>\n",
       "      <td>-74.033459</td>\n",
       "      <td>Manila &amp; 1st</td>\n",
       "      <td>40.721651</td>\n",
       "      <td>-74.042884</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tripduration                 starttime                  stoptime  \\\n",
       "0           142  2019-02-01 15:35:02.0820  2019-02-01 15:37:24.1360   \n",
       "1           223  2019-02-01 17:00:46.8900  2019-02-01 17:04:30.5500   \n",
       "2           106  2019-02-01 17:08:01.3260  2019-02-01 17:09:47.4400   \n",
       "3           370  2019-02-01 17:09:31.2100  2019-02-01 17:15:41.6550   \n",
       "4           315  2019-02-01 17:19:53.2490  2019-02-01 17:25:09.1400   \n",
       "\n",
       "  start station name  start station latitude  start station longitude  \\\n",
       "0     Exchange Place               40.716247               -74.033459   \n",
       "1     Exchange Place               40.716247               -74.033459   \n",
       "2     Exchange Place               40.716247               -74.033459   \n",
       "3     Exchange Place               40.716247               -74.033459   \n",
       "4     Exchange Place               40.716247               -74.033459   \n",
       "\n",
       "  end station name  end station latitude  end station longitude    usertype  \\\n",
       "0       Harborside             40.719252             -74.034234  Subscriber   \n",
       "1         Grand St             40.715178             -74.037683  Subscriber   \n",
       "2      Paulus Hook             40.714145             -74.033552  Subscriber   \n",
       "3       Newark Ave             40.721525             -74.046305  Subscriber   \n",
       "4     Manila & 1st             40.721651             -74.042884  Subscriber   \n",
       "\n",
       "   birth year  gender  \n",
       "0      1963.0       1  \n",
       "1      1992.0       2  \n",
       "2      1960.0       1  \n",
       "3      1976.0       1  \n",
       "4      1980.0       1  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from os.path import dirname, abspath\n",
    "from datetime import datetime\n",
    "\n",
    "d = dirname(dirname(abspath(\"preprocessing.ipynb\")))\n",
    "df = pd.read_csv(d + '/data/Full_Concat.csv')\n",
    "\n",
    "df1 = df.drop(columns=['start station id', 'end station id', 'bikeid','Unnamed: 0'])\n",
    "print(df1.shape)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(759807, 12)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new data frame with split value columns \n",
    "starts = df1['starttime'].str.split(\" \", n = 1, expand = True) \n",
    "ends = df1['stoptime'].str.split(\" \", n = 1, expand = True) \n",
    "\n",
    "  \n",
    "# making separate last name column from new data frame \n",
    "df1['Start Time']= starts[1] \n",
    "df1['End Time']= ends[1] \n",
    "  \n",
    "# Dropping old Name columns \n",
    "df1.drop(columns =['starttime','stoptime'], inplace = True) \n",
    "\n",
    "df1['Start Time'] = df1['Start Time'].map(lambda x: pd.Timestamp(x))\n",
    "df1['End Time'] = df1['End Time'].map(lambda x: pd.Timestamp(x))\n",
    "\n",
    "min_time = min(min(df1['Start Time']),min(df1['End Time']))\n",
    "\n",
    "df1['Start Time'] = df1['Start Time'].map(lambda x: pd.Timedelta(x - min_time))\n",
    "df1['End Time'] = df1['End Time'].map(lambda x: pd.Timedelta(x - min_time))\n",
    "\n",
    "df1['Start Time'] = df1['Start Time'].dt.total_seconds()\n",
    "df1['End Time'] = df1['End Time'].dt.total_seconds()\n",
    "\n",
    "df1.head()\n",
    "df1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(d + '/data/Semi_processed_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_ftrs = ['start station name', 'end station name', 'gender']\n",
    "cont_ftrs = ['tripduration','start station longitude', 'end station longitude','start station latitude',\n",
    "             'end station latitude','Start Time','End Time','birth year']\n",
    "label = ['usertype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Label Encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "df_usertype = pd.DataFrame(le.fit_transform(df1['usertype'].to_numpy().reshape(-1,1)), columns = label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot Encoder\n",
    "\n",
    "#start station name\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "df_start_station = pd.DataFrame(enc.fit_transform(df1['start station name'].to_numpy().reshape(-1,1)))\n",
    "df_start_station.columns = enc.get_feature_names()\n",
    "\n",
    "\n",
    "#end station name\n",
    "df_end_station = pd.DataFrame(enc.fit_transform(df1['end station name'].to_numpy().reshape(-1,1)))\n",
    "df_end_station.columns = enc.get_feature_names()\n",
    "\n",
    "#gender\n",
    "df_gender = pd.DataFrame(enc.fit_transform(df1['gender'].to_numpy().reshape(-1,1)))\n",
    "df_gender.columns = enc.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(759807, 254)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge dfs\n",
    "df_all = pd.concat([df_usertype, df_start_station, df_end_station,\n",
    "                    df_gender],axis = 1)\n",
    "\n",
    "df2 = df1\n",
    "\n",
    "df2 = df2.drop(['usertype', 'start station name', 'end station name',\n",
    "                'gender'], axis = 1)\n",
    "\n",
    "df_mcar = pd.concat([df2, df_all],axis = 1)\n",
    "\n",
    "df_mcar.shape\n",
    "#df_mcar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MCAR TEST\n",
    "\n",
    "# from the pymice package \n",
    "# https://github.com/RianneSchouten/pymice\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as ma\n",
    "import scipy.stats as st\n",
    "\n",
    "def checks_input_mcar_tests(data):\n",
    "    \"\"\" Checks whether the input parameter of class McarTests is correct\n",
    "            Parameters\n",
    "            ----------\n",
    "            data:\n",
    "                The input of McarTests specified as 'data'\n",
    "            Returns\n",
    "            -------\n",
    "            bool\n",
    "                True if input is correct\n",
    "            \"\"\"\n",
    "\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        print(\"Error: Data should be a Pandas DataFrame\")\n",
    "        return False\n",
    "\n",
    "    if not any(data.dtypes.values == np.float):\n",
    "        if not any(data.dtypes.values == np.int):\n",
    "            print(\"Error: Dataset cannot contain other value types than floats and/or integers\")\n",
    "            return False\n",
    "\n",
    "    if not data.isnull().values.any():\n",
    "        print(\"Error: No NaN's in given data\")\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def mcar_test(data):\n",
    "    \"\"\" Implementation of Little's MCAR test\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: Pandas DataFrame\n",
    "        An incomplete dataset with samples as index and variables as columns\n",
    "    Returns\n",
    "    -------\n",
    "    p_value: Float\n",
    "        This value is the outcome of a chi-square statistical test, testing whether the null hypothesis\n",
    "        'the missingness mechanism of the incomplete dataset is MCAR' can be rejected.\n",
    "    \"\"\"\n",
    "\n",
    "    if not checks_input_mcar_tests(data):\n",
    "        raise Exception(\"Input not correct\")\n",
    "\n",
    "    dataset = data.copy()\n",
    "    vars = dataset.dtypes.index.values\n",
    "    n_var = dataset.shape[1]\n",
    "\n",
    "    # mean and covariance estimates\n",
    "    # ideally, this is done with a maximum likelihood estimator\n",
    "    gmean = dataset.mean()\n",
    "    gcov = dataset.cov()\n",
    "\n",
    "    # set up missing data patterns\n",
    "    r = 1 * dataset.isnull()\n",
    "    mdp = np.dot(r, list(map(lambda x: ma.pow(2, x), range(n_var))))\n",
    "    sorted_mdp = sorted(np.unique(mdp))\n",
    "    n_pat = len(sorted_mdp)\n",
    "    correct_mdp = list(map(lambda x: sorted_mdp.index(x), mdp))\n",
    "    dataset['mdp'] = pd.Series(correct_mdp, index=dataset.index)\n",
    "\n",
    "    # calculate statistic and df\n",
    "    pj = 0\n",
    "    d2 = 0\n",
    "    for i in range(n_pat):\n",
    "        dataset_temp = dataset.loc[dataset['mdp'] == i, vars]\n",
    "        select_vars = ~dataset_temp.isnull().any()\n",
    "        pj += np.sum(select_vars)\n",
    "        select_vars = vars[select_vars]\n",
    "        means = dataset_temp[select_vars].mean() - gmean[select_vars]\n",
    "        select_cov = gcov.loc[select_vars, select_vars]\n",
    "        mj = len(dataset_temp)\n",
    "        parta = np.dot(means.T, np.linalg.solve(select_cov, np.identity(select_cov.shape[1])))\n",
    "        d2 += mj * (np.dot(parta, means))\n",
    "\n",
    "    df = pj - n_var\n",
    "\n",
    "    # perform test and save output\n",
    "    p_value = 1 - st.chi2.cdf(d2, df)\n",
    "\n",
    "    return p_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checks_input_mcar_tests(df_mcar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mcar_test(df_mcar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(759807, 12)\n",
      "tripduration               0.000000\n",
      "start station name         0.000000\n",
      "start station latitude     0.000000\n",
      "start station longitude    0.000000\n",
      "end station name           0.000000\n",
      "end station latitude       0.000000\n",
      "end station longitude      0.000000\n",
      "usertype                   0.000000\n",
      "birth year                 0.011198\n",
      "gender                     0.000000\n",
      "Start Time                 0.000000\n",
      "End Time                   0.000000\n",
      "dtype: float64\n",
      "0.011197580438190224\n"
     ]
    }
   ],
   "source": [
    "print(df1.shape)\n",
    "print(df1.isnull().sum(axis=0)/df1.shape[0])\n",
    "print(sum(df1.isnull().sum(axis=1)!=0)/df1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(759807, 12)\n",
      "(751299, 12)\n"
     ]
    }
   ],
   "source": [
    "#drop missing rows\n",
    "print(df1.shape)\n",
    "# by default, rows/points are dropped\n",
    "df2 = df1.dropna()\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standart Scaler\n",
    "\n",
    "#trip durration\n",
    "scaler = StandardScaler()\n",
    "df_trip_durration = pd.DataFrame(scaler.fit_transform(df_mcar['tripduration'].to_numpy().reshape(-1,1)))\n",
    "df_trip_durration.columns = ['tripduration']\n",
    "\n",
    "#start station longitude\n",
    "df_start_staationlon = pd.DataFrame(scaler.fit_transform(df_mcar['start station longitude'].to_numpy().reshape(-1,1)))\n",
    "df_start_staationlon.columns = ['start station longitude']\n",
    "\n",
    "#end station longitude\n",
    "df_end_staationlon = pd.DataFrame(scaler.fit_transform(df_mcar['end station longitude'].to_numpy().reshape(-1,1)))\n",
    "df_end_staationlon.columns = ['end station longitude']\n",
    "\n",
    "#start station latitude\n",
    "df_start_stationlat = pd.DataFrame(scaler.fit_transform(df_mcar['start station latitude'].to_numpy().reshape(-1,1)))\n",
    "df_start_stationlat.columns = ['start station latitude']\n",
    "\n",
    "#end station latitude\n",
    "df_end_stationlat = pd.DataFrame(scaler.fit_transform(df_mcar['end station latitude'].to_numpy().reshape(-1,1)))\n",
    "df_end_stationlat.columns = ['end station latitude']\n",
    "\n",
    "#Start Time\n",
    "df_start_time = pd.DataFrame(scaler.fit_transform(df_mcar['Start Time'].to_numpy().reshape(-1,1)))\n",
    "df_start_time.columns = ['Start Time']\n",
    "\n",
    "#End Time\n",
    "df_end_time = pd.DataFrame(scaler.fit_transform(df_mcar['End Time'].to_numpy().reshape(-1,1)))\n",
    "df_end_time.columns = ['End Time']\n",
    "\n",
    "#birth year\n",
    "df_birth_year = pd.DataFrame(scaler.fit_transform(df_mcar['birth year'].to_numpy().reshape(-1,1)))\n",
    "df_birth_year.columns = ['birth year']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usertype</th>\n",
       "      <th>x0_5 Corners Library</th>\n",
       "      <th>x0_Astor Place</th>\n",
       "      <th>x0_Baldwin at Montgomery</th>\n",
       "      <th>x0_Bayside Park</th>\n",
       "      <th>x0_Bergen Ave</th>\n",
       "      <th>x0_Bethune Center</th>\n",
       "      <th>x0_Brunswick &amp; 6th</th>\n",
       "      <th>x0_Brunswick St</th>\n",
       "      <th>x0_Christ Hospital</th>\n",
       "      <th>...</th>\n",
       "      <th>x0_1</th>\n",
       "      <th>x0_2</th>\n",
       "      <th>birth year</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>end station latitude</th>\n",
       "      <th>start station latitude</th>\n",
       "      <th>end station longitude</th>\n",
       "      <th>start station longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.718326</td>\n",
       "      <td>0.280763</td>\n",
       "      <td>0.280763</td>\n",
       "      <td>-0.067222</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>-0.886967</td>\n",
       "      <td>-0.027368</td>\n",
       "      <td>1.178391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.105304</td>\n",
       "      <td>0.559398</td>\n",
       "      <td>0.559398</td>\n",
       "      <td>-0.057472</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>-0.886967</td>\n",
       "      <td>-0.028819</td>\n",
       "      <td>1.178391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.010425</td>\n",
       "      <td>0.582926</td>\n",
       "      <td>0.582926</td>\n",
       "      <td>-0.071555</td>\n",
       "      <td>0.025945</td>\n",
       "      <td>-0.886967</td>\n",
       "      <td>-0.027081</td>\n",
       "      <td>1.178391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.452561</td>\n",
       "      <td>0.587794</td>\n",
       "      <td>0.587794</td>\n",
       "      <td>-0.039778</td>\n",
       "      <td>0.031589</td>\n",
       "      <td>-0.886967</td>\n",
       "      <td>-0.032445</td>\n",
       "      <td>1.178391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.063095</td>\n",
       "      <td>0.621483</td>\n",
       "      <td>0.621483</td>\n",
       "      <td>-0.046398</td>\n",
       "      <td>0.031685</td>\n",
       "      <td>-0.886967</td>\n",
       "      <td>-0.031007</td>\n",
       "      <td>1.178391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 254 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   usertype  x0_5 Corners Library  x0_Astor Place  x0_Baldwin at Montgomery  \\\n",
       "0         1                   0.0             0.0                       0.0   \n",
       "1         1                   0.0             0.0                       0.0   \n",
       "2         1                   0.0             0.0                       0.0   \n",
       "3         1                   0.0             0.0                       0.0   \n",
       "4         1                   0.0             0.0                       0.0   \n",
       "\n",
       "   x0_Bayside Park  x0_Bergen Ave  x0_Bethune Center  x0_Brunswick & 6th  \\\n",
       "0              0.0            0.0                0.0                 0.0   \n",
       "1              0.0            0.0                0.0                 0.0   \n",
       "2              0.0            0.0                0.0                 0.0   \n",
       "3              0.0            0.0                0.0                 0.0   \n",
       "4              0.0            0.0                0.0                 0.0   \n",
       "\n",
       "   x0_Brunswick St  x0_Christ Hospital  ...  x0_1  x0_2  birth year  \\\n",
       "0              0.0                 0.0  ...   1.0   0.0   -1.718326   \n",
       "1              0.0                 0.0  ...   0.0   1.0    1.105304   \n",
       "2              0.0                 0.0  ...   1.0   0.0   -2.010425   \n",
       "3              0.0                 0.0  ...   1.0   0.0   -0.452561   \n",
       "4              0.0                 0.0  ...   1.0   0.0   -0.063095   \n",
       "\n",
       "   Start Time  Start Time  tripduration  end station latitude  \\\n",
       "0    0.280763    0.280763     -0.067222              0.029851   \n",
       "1    0.559398    0.559398     -0.057472              0.026735   \n",
       "2    0.582926    0.582926     -0.071555              0.025945   \n",
       "3    0.587794    0.587794     -0.039778              0.031589   \n",
       "4    0.621483    0.621483     -0.046398              0.031685   \n",
       "\n",
       "   start station latitude  end station longitude  start station longitude  \n",
       "0               -0.886967              -0.027368                 1.178391  \n",
       "1               -0.886967              -0.028819                 1.178391  \n",
       "2               -0.886967              -0.027081                 1.178391  \n",
       "3               -0.886967              -0.032445                 1.178391  \n",
       "4               -0.886967              -0.031007                 1.178391  \n",
       "\n",
       "[5 rows x 254 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge dfs\n",
    "df_all2 = pd.concat([df_birth_year, df_start_time, df_start_time, df_trip_durration,\n",
    "                    df_end_stationlat, df_start_stationlat, df_end_staationlon, df_start_staationlon],axis = 1)\n",
    "\n",
    "df3 = df_mcar\n",
    "\n",
    "df3 = df3.drop(['tripduration','start station longitude',\n",
    "                                        'end station longitude','start station latitude',\n",
    "                                        'end station latitude','Start Time','End Time',\n",
    "                                        'birth year'], axis = 1)\n",
    "\n",
    "df_preprocessed = pd.concat([df3, df_all2],axis = 1)\n",
    "\n",
    "df_preprocessed.shape\n",
    "df_preprocessed.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed.to_csv(d + '/data/Preprocessed_Citi_Bike_Data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
