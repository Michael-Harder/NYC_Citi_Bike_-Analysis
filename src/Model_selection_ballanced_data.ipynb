{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* test the model on a df with an equal number of user types to test how good the model really is at classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import dirname, abspath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22794, 12)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = dirname(dirname(abspath(\"preprocessing.ipynb\")))\n",
    "df_wokring = pd.read_csv(d + '/data/Semi_processed_data.csv') #nrows = 1000)\n",
    "\n",
    "df = df_wokring.sample(frac=0.03, replace=False, random_state=22) #3% smaple from df for 22794 observations\n",
    "\n",
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(df)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nans = lambda df: df[df.isnull().any(axis=1)]\n",
    "nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['birth year','start station latitude','end station latitude',\n",
    "        'start station longitude', 'end station longitude'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22794, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>start station name</th>\n",
       "      <th>end station name</th>\n",
       "      <th>usertype</th>\n",
       "      <th>gender</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>End Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35922</th>\n",
       "      <td>224</td>\n",
       "      <td>Jersey &amp; 6th St</td>\n",
       "      <td>Grove St PATH</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1</td>\n",
       "      <td>32214.436</td>\n",
       "      <td>32438.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493350</th>\n",
       "      <td>217</td>\n",
       "      <td>Grove St PATH</td>\n",
       "      <td>Marin Light Rail</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1</td>\n",
       "      <td>73627.443</td>\n",
       "      <td>73845.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558429</th>\n",
       "      <td>680</td>\n",
       "      <td>Riverview Park</td>\n",
       "      <td>Hilltop</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1</td>\n",
       "      <td>76253.519</td>\n",
       "      <td>76934.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285744</th>\n",
       "      <td>228</td>\n",
       "      <td>McGinley Square</td>\n",
       "      <td>Sip Ave</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>2</td>\n",
       "      <td>24314.744</td>\n",
       "      <td>24543.641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455471</th>\n",
       "      <td>387</td>\n",
       "      <td>Newport Pkwy</td>\n",
       "      <td>Harborside</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>2</td>\n",
       "      <td>58258.963</td>\n",
       "      <td>58646.882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tripduration start station name  end station name    usertype  gender  \\\n",
       "35922            224    Jersey & 6th St     Grove St PATH  Subscriber       1   \n",
       "493350           217      Grove St PATH  Marin Light Rail  Subscriber       1   \n",
       "558429           680     Riverview Park           Hilltop  Subscriber       1   \n",
       "285744           228    McGinley Square           Sip Ave  Subscriber       2   \n",
       "455471           387       Newport Pkwy        Harborside  Subscriber       2   \n",
       "\n",
       "        Start Time   End Time  \n",
       "35922    32214.436  32438.436  \n",
       "493350   73627.443  73845.094  \n",
       "558429   76253.519  76934.417  \n",
       "285744   24314.744  24543.641  \n",
       "455471   58258.963  58646.882  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Customers = df[df['usertype'] == 'Customer']\n",
    "df_Subscribers = df[df['usertype'] == 'Subscriber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1747, 7)\n",
      "(21047, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>start station name</th>\n",
       "      <th>end station name</th>\n",
       "      <th>usertype</th>\n",
       "      <th>gender</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>End Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199183</th>\n",
       "      <td>301</td>\n",
       "      <td>Grove St PATH</td>\n",
       "      <td>Marin Light Rail</td>\n",
       "      <td>Customer</td>\n",
       "      <td>2</td>\n",
       "      <td>53853.371</td>\n",
       "      <td>54154.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380568</th>\n",
       "      <td>273</td>\n",
       "      <td>McGinley Square</td>\n",
       "      <td>Sip Ave</td>\n",
       "      <td>Customer</td>\n",
       "      <td>0</td>\n",
       "      <td>56315.436</td>\n",
       "      <td>56589.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562728</th>\n",
       "      <td>676</td>\n",
       "      <td>Hilltop</td>\n",
       "      <td>Grand St</td>\n",
       "      <td>Customer</td>\n",
       "      <td>0</td>\n",
       "      <td>8563.948</td>\n",
       "      <td>9240.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586084</th>\n",
       "      <td>1391</td>\n",
       "      <td>Liberty Light Rail</td>\n",
       "      <td>Grand St</td>\n",
       "      <td>Customer</td>\n",
       "      <td>2</td>\n",
       "      <td>47530.919</td>\n",
       "      <td>48921.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538032</th>\n",
       "      <td>818</td>\n",
       "      <td>Morris Canal</td>\n",
       "      <td>JC Medical Center</td>\n",
       "      <td>Customer</td>\n",
       "      <td>2</td>\n",
       "      <td>53443.451</td>\n",
       "      <td>54261.608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tripduration  start station name   end station name  usertype  gender  \\\n",
       "199183           301       Grove St PATH   Marin Light Rail  Customer       2   \n",
       "380568           273     McGinley Square            Sip Ave  Customer       0   \n",
       "562728           676             Hilltop           Grand St  Customer       0   \n",
       "586084          1391  Liberty Light Rail           Grand St  Customer       2   \n",
       "538032           818        Morris Canal  JC Medical Center  Customer       2   \n",
       "\n",
       "        Start Time   End Time  \n",
       "199183   53853.371  54154.813  \n",
       "380568   56315.436  56589.436  \n",
       "562728    8563.948   9240.721  \n",
       "586084   47530.919  48921.950  \n",
       "538032   53443.451  54261.608  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_Customers.shape)\n",
    "print(df_Subscribers.shape)\n",
    "df_Customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cust_sampled = df_Customers.sample(df_Customers.shape[0]//2)\n",
    "df_subs_sampled = df_Subscribers.sample(df_Customers.shape[0]//2)\n",
    "df_balanced = pd.concat([df_cust_sampled,df_subs_sampled], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1746, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>start station name</th>\n",
       "      <th>end station name</th>\n",
       "      <th>usertype</th>\n",
       "      <th>gender</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>End Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>404404</th>\n",
       "      <td>1209</td>\n",
       "      <td>Exchange Place</td>\n",
       "      <td>Liberty Light Rail</td>\n",
       "      <td>Customer</td>\n",
       "      <td>0</td>\n",
       "      <td>68472.132</td>\n",
       "      <td>69681.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250825</th>\n",
       "      <td>1582</td>\n",
       "      <td>York St</td>\n",
       "      <td>Riverview Park</td>\n",
       "      <td>Customer</td>\n",
       "      <td>0</td>\n",
       "      <td>51327.256</td>\n",
       "      <td>52909.285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319443</th>\n",
       "      <td>1300</td>\n",
       "      <td>Newport Pkwy</td>\n",
       "      <td>Newport Pkwy</td>\n",
       "      <td>Customer</td>\n",
       "      <td>0</td>\n",
       "      <td>74054.543</td>\n",
       "      <td>75354.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553427</th>\n",
       "      <td>2707</td>\n",
       "      <td>Washington St</td>\n",
       "      <td>Hamilton Park</td>\n",
       "      <td>Customer</td>\n",
       "      <td>0</td>\n",
       "      <td>57600.254</td>\n",
       "      <td>60307.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686315</th>\n",
       "      <td>1135</td>\n",
       "      <td>Exchange Place</td>\n",
       "      <td>Lafayette Park</td>\n",
       "      <td>Customer</td>\n",
       "      <td>0</td>\n",
       "      <td>73523.190</td>\n",
       "      <td>74658.342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tripduration start station name    end station name  usertype  gender  \\\n",
       "404404          1209     Exchange Place  Liberty Light Rail  Customer       0   \n",
       "250825          1582            York St      Riverview Park  Customer       0   \n",
       "319443          1300       Newport Pkwy        Newport Pkwy  Customer       0   \n",
       "553427          2707      Washington St       Hamilton Park  Customer       0   \n",
       "686315          1135     Exchange Place      Lafayette Park  Customer       0   \n",
       "\n",
       "        Start Time   End Time  \n",
       "404404   68472.132  69681.146  \n",
       "250825   51327.256  52909.285  \n",
       "319443   74054.543  75354.771  \n",
       "553427   57600.254  60307.968  \n",
       "686315   73523.190  74658.342  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_balanced.shape)\n",
    "df_balanced.head() 1746"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['start station name', 'end station name', 'gender',\n",
    "                 'tripduration', 'Start Time','End Time']\n",
    "\n",
    "label = 'usertype'\n",
    "user_type = df_balanced[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.drop(['usertype'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(df_balanced)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nans = lambda df_balanced: df_balanced[df_balanced.isnull().any(axis=1)]\n",
    "nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1746, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>start station name</th>\n",
       "      <th>end station name</th>\n",
       "      <th>gender</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>End Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>404404</th>\n",
       "      <td>1209</td>\n",
       "      <td>Exchange Place</td>\n",
       "      <td>Liberty Light Rail</td>\n",
       "      <td>0</td>\n",
       "      <td>68472.132</td>\n",
       "      <td>69681.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250825</th>\n",
       "      <td>1582</td>\n",
       "      <td>York St</td>\n",
       "      <td>Riverview Park</td>\n",
       "      <td>0</td>\n",
       "      <td>51327.256</td>\n",
       "      <td>52909.285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319443</th>\n",
       "      <td>1300</td>\n",
       "      <td>Newport Pkwy</td>\n",
       "      <td>Newport Pkwy</td>\n",
       "      <td>0</td>\n",
       "      <td>74054.543</td>\n",
       "      <td>75354.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553427</th>\n",
       "      <td>2707</td>\n",
       "      <td>Washington St</td>\n",
       "      <td>Hamilton Park</td>\n",
       "      <td>0</td>\n",
       "      <td>57600.254</td>\n",
       "      <td>60307.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686315</th>\n",
       "      <td>1135</td>\n",
       "      <td>Exchange Place</td>\n",
       "      <td>Lafayette Park</td>\n",
       "      <td>0</td>\n",
       "      <td>73523.190</td>\n",
       "      <td>74658.342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tripduration start station name    end station name  gender  \\\n",
       "404404          1209     Exchange Place  Liberty Light Rail       0   \n",
       "250825          1582            York St      Riverview Park       0   \n",
       "319443          1300       Newport Pkwy        Newport Pkwy       0   \n",
       "553427          2707      Washington St       Hamilton Park       0   \n",
       "686315          1135     Exchange Place      Lafayette Park       0   \n",
       "\n",
       "        Start Time   End Time  \n",
       "404404   68472.132  69681.146  \n",
       "250825   51327.256  52909.285  \n",
       "319443   74054.543  75354.771  \n",
       "553427   57600.254  60307.968  \n",
       "686315   73523.190  74658.342  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_balanced.shape)\n",
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404404    Customer\n",
       "250825    Customer\n",
       "319443    Customer\n",
       "553427    Customer\n",
       "686315    Customer\n",
       "Name: usertype, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer      0.5\n",
       "Subscriber    0.5\n",
       "Name: usertype, dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance = user_type.value_counts(normalize = True)\n",
    "balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance of the data / baseline accuracy =  0.5\n"
     ]
    }
   ],
   "source": [
    "base = balance[0]\n",
    "print(\"balance of the data / baseline accuracy = \",base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import statistics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import matplotlib\n",
    "from matplotlib import pylab as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_pipeline_kfold_GridSearchCV_log(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state,stratify=y)\n",
    "    # splitter for _other\n",
    "    kf = StratifiedKFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    \n",
    "    feature_names = ['start station name', 'end station name', 'gender',\n",
    "                     'tripduration', 'Start Time','End Time']\n",
    "\n",
    "    cat_ftrs = ['start station name', 'end station name', 'gender']\n",
    "    num_ftrs = ['tripduration', 'Start Time','End Time']\n",
    "    \n",
    "    cat_ftrs_i = [df_balanced.columns.get_loc(x) for x in cat_ftrs]\n",
    "    num_ftrs_i = [df_balanced.columns.get_loc(x) for x in num_ftrs]\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(sparse=False, handle_unknown = 'ignore'))])\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "\n",
    "    # collect the transformers\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_ftrs_i),\n",
    "            ('cat', categorical_transformer, cat_ftrs_i)]) \n",
    "\n",
    "    pipe = make_pipeline(preprocessor, LogisticRegression(penalty='l1', solver='saga',\n",
    "                                                          max_iter=10000, multi_class = 'auto', random_state = 22))\n",
    "    #pipe = make_pipeline(preprocess, LogisticRegression(penalty='l1', solver='saga', max_iter=10000))\n",
    "    \n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'logisticregression__C': [0.1, 1.0, 10, 100]}\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(accuracy_score),\n",
    "                            cv=kf, return_train_score = True,iid=True)\n",
    "    # do kfold CV on _other\n",
    "    print(\"running\")\n",
    "    grid.fit(X_other, y_other)\n",
    "    return grid, grid.score(X_test, y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_balanced.loc[:,df_balanced.columns != label].values\n",
    "y = user_type.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "{'logisticregression__C': 1.0}\n",
      "best CV score: 0.8094555873925502\n",
      "test score: 0.8542857142857143\n",
      "running\n",
      "{'logisticregression__C': 1.0}\n",
      "best CV score: 0.8316618911174785\n",
      "test score: 0.8114285714285714\n",
      "running\n",
      "{'logisticregression__C': 1.0}\n",
      "best CV score: 0.8166189111747851\n",
      "test score: 0.8457142857142858\n",
      "running\n",
      "{'logisticregression__C': 10}\n",
      "best CV score: 0.8180515759312321\n",
      "test score: 0.8171428571428572\n",
      "running\n",
      "{'logisticregression__C': 1.0}\n",
      "best CV score: 0.826647564469914\n",
      "test score: 0.8114285714285714\n",
      "running\n",
      "{'logisticregression__C': 1.0}\n",
      "best CV score: 0.8173352435530086\n",
      "test score: 0.8457142857142858\n",
      "running\n",
      "{'logisticregression__C': 1.0}\n",
      "best CV score: 0.8187679083094556\n",
      "test score: 0.8285714285714286\n",
      "running\n",
      "{'logisticregression__C': 100}\n",
      "best CV score: 0.8244985673352435\n",
      "test score: 0.8\n",
      "running\n",
      "{'logisticregression__C': 1.0}\n",
      "best CV score: 0.8159025787965616\n",
      "test score: 0.8228571428571428\n",
      "running\n",
      "{'logisticregression__C': 1.0}\n",
      "best CV score: 0.8237822349570201\n",
      "test score: 0.8028571428571428\n",
      "test accuracy: 0.82 +/- 0.02\n"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "\n",
    "for i in range(10):\n",
    "    grid, test_score = ML_pipeline_kfold_GridSearchCV_log(X,y.ravel(),i*22, 5)\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "print('test accuracy:',np.around(np.mean(test_scores),2),'+/-',np.around(np.std(test_scores),2))\n",
    "\n",
    "mean_LR_a = np.mean(test_scores)\n",
    "mean_LR_sd = np.std(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.8240000000000001\n",
      "sd:  0.01807919087949302\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy:\",mean_LR_a)\n",
    "print(\"sd: \",mean_LR_sd) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_score = 17.92115599418273\n"
     ]
    }
   ],
   "source": [
    "LR_score = (mean_LR_a - base)/mean_LR_sd\n",
    "\n",
    "print(\"LR_score =\",LR_score) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **RF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_pipeline_kfold_GridSearchCV_RF(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state,stratify=y)\n",
    "    # splitter for _other\n",
    "    kf = StratifiedKFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    \n",
    "    feature_names = ['start station name', 'end station name', 'gender',\n",
    "                     'tripduration', 'Start Time','End Time']\n",
    "\n",
    "    cat_ftrs = ['start station name', 'end station name', 'gender']\n",
    "    num_ftrs = ['tripduration', 'Start Time','End Time']\n",
    "    \n",
    "    cat_ftrs_i = [df_balanced.columns.get_loc(x) for x in cat_ftrs]\n",
    "    num_ftrs_i = [df_balanced.columns.get_loc(x) for x in num_ftrs]\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(sparse=False, handle_unknown = 'ignore'))])\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "\n",
    "    # collect the transformers\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_ftrs_i),\n",
    "            ('cat', categorical_transformer, cat_ftrs_i)]) \n",
    "\n",
    "    pipe = make_pipeline(preprocessor, RandomForestClassifier(random_state = 22))\n",
    "    #pipe = make_pipeline(preprocess, LogisticRegression(penalty='l1', solver='saga', max_iter=10000))\n",
    "    \n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'randomforestclassifier__min_samples_split': range(2,25,5),\n",
    "                  'randomforestclassifier__max_depth': range(1,30,5)}\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(accuracy_score),\n",
    "                            cv=kf, return_train_score = True,iid=True)\n",
    "    # do kfold CV on _other\n",
    "    print(\"running\")\n",
    "    grid.fit(X_other, y_other)\n",
    "    return grid, grid.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "{'randomforestclassifier__max_depth': 26, 'randomforestclassifier__min_samples_split': 12}\n",
      "best CV score: 0.8273638968481375\n",
      "test score: 0.8485714285714285\n",
      "running\n",
      "{'randomforestclassifier__max_depth': 11, 'randomforestclassifier__min_samples_split': 7}\n",
      "best CV score: 0.8431232091690545\n",
      "test score: 0.8285714285714286\n",
      "running\n",
      "{'randomforestclassifier__max_depth': 21, 'randomforestclassifier__min_samples_split': 7}\n",
      "best CV score: 0.8259312320916905\n",
      "test score: 0.8371428571428572\n",
      "running\n",
      "{'randomforestclassifier__max_depth': 26, 'randomforestclassifier__min_samples_split': 12}\n",
      "best CV score: 0.8388252148997135\n",
      "test score: 0.8142857142857143\n",
      "running\n",
      "{'randomforestclassifier__max_depth': 26, 'randomforestclassifier__min_samples_split': 12}\n",
      "best CV score: 0.8402578796561605\n",
      "test score: 0.8171428571428572\n",
      "running\n",
      "{'randomforestclassifier__max_depth': 11, 'randomforestclassifier__min_samples_split': 2}\n",
      "best CV score: 0.833810888252149\n",
      "test score: 0.8457142857142858\n",
      "running\n",
      "{'randomforestclassifier__max_depth': 6, 'randomforestclassifier__min_samples_split': 7}\n",
      "best CV score: 0.8244985673352435\n",
      "test score: 0.8285714285714286\n",
      "running\n",
      "{'randomforestclassifier__max_depth': 16, 'randomforestclassifier__min_samples_split': 17}\n",
      "best CV score: 0.8330945558739254\n",
      "test score: 0.8085714285714286\n",
      "running\n",
      "{'randomforestclassifier__max_depth': 11, 'randomforestclassifier__min_samples_split': 7}\n",
      "best CV score: 0.8330945558739254\n",
      "test score: 0.8142857142857143\n",
      "running\n",
      "{'randomforestclassifier__max_depth': 11, 'randomforestclassifier__min_samples_split': 2}\n",
      "best CV score: 0.833810888252149\n",
      "test score: 0.82\n",
      "test accuracy: 0.83 +/- 0.01\n"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "\n",
    "for i in range(10):\n",
    "    grid, test_score = ML_pipeline_kfold_GridSearchCV_RF(X,y.ravel(),i*22, 5)\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "print('test accuracy:',np.around(np.mean(test_scores),2),'+/-',np.around(np.std(test_scores),2))\n",
    "\n",
    "mean_RF_a = np.mean(test_scores)\n",
    "mean_RF_sd = np.std(test_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.8262857142857142\n",
      "sd:  0.013142857142857145\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy:\",mean_RF_a) \n",
    "print(\"sd: \",mean_RF_sd) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF_score = 24.826086956521728\n"
     ]
    }
   ],
   "source": [
    "RF_score = (mean_RF_a - base)/mean_RF_sd\n",
    "\n",
    "print(\"RF_score =\",RF_score) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **saving RF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_pipeline_kfold_GridSearchCV_RF_3(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state,stratify=y)\n",
    "    # splitter for _other\n",
    "    kf = StratifiedKFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    \n",
    "    feature_names = ['start station name', 'end station name', 'gender',\n",
    "                     'tripduration', 'Start Time','End Time']\n",
    "\n",
    "    cat_ftrs = ['start station name', 'end station name', 'gender']\n",
    "    num_ftrs = ['tripduration', 'Start Time','End Time']\n",
    "    \n",
    "    cat_ftrs_i = [df_balanced.columns.get_loc(x) for x in cat_ftrs]\n",
    "    num_ftrs_i = [df_balanced.columns.get_loc(x) for x in num_ftrs]\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(sparse=False, handle_unknown = 'ignore'))])\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "\n",
    "    # collect the transformers\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_ftrs_i),\n",
    "            ('cat', categorical_transformer, cat_ftrs_i)]) \n",
    "\n",
    "    pipe = make_pipeline(preprocessor, RandomForestClassifier(random_state = 22))\n",
    "    #pipe = make_pipeline(preprocess, LogisticRegression(penalty='l1', solver='saga', max_iter=10000))\n",
    "    \n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'randomforestclassifier__min_samples_split': range(2,25,5),\n",
    "                  'randomforestclassifier__max_depth': range(1,30,5)}\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(accuracy_score),\n",
    "                            cv=kf, return_train_score = True,iid=True)\n",
    "    # do kfold CV on _other\n",
    "    print(\"running\")\n",
    "    grid.fit(X_other, y_other)\n",
    "    return grid, X_test, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "0.8223495702005731\n",
      "0.86\n",
      "{'randomforestclassifier__max_depth': 21, 'randomforestclassifier__min_samples_split': 22}\n",
      "running\n",
      "0.832378223495702\n",
      "0.8028571428571428\n",
      "{'randomforestclassifier__max_depth': 26, 'randomforestclassifier__min_samples_split': 2}\n",
      "running\n",
      "0.8273638968481375\n",
      "0.8457142857142858\n",
      "{'randomforestclassifier__max_depth': 21, 'randomforestclassifier__min_samples_split': 17}\n",
      "running\n",
      "0.833810888252149\n",
      "0.8028571428571428\n",
      "{'randomforestclassifier__max_depth': 16, 'randomforestclassifier__min_samples_split': 2}\n",
      "running\n",
      "0.835243553008596\n",
      "0.8257142857142857\n",
      "{'randomforestclassifier__max_depth': 26, 'randomforestclassifier__min_samples_split': 22}\n",
      "running\n",
      "0.8259312320916905\n",
      "0.8171428571428572\n",
      "{'randomforestclassifier__max_depth': 21, 'randomforestclassifier__min_samples_split': 17}\n",
      "running\n",
      "0.8302292263610315\n",
      "0.82\n",
      "{'randomforestclassifier__max_depth': 11, 'randomforestclassifier__min_samples_split': 2}\n",
      "running\n",
      "0.8316618911174785\n",
      "0.7971428571428572\n",
      "{'randomforestclassifier__max_depth': 11, 'randomforestclassifier__min_samples_split': 12}\n",
      "running\n",
      "0.830945558739255\n",
      "0.8142857142857143\n",
      "{'randomforestclassifier__max_depth': 11, 'randomforestclassifier__min_samples_split': 22}\n",
      "running\n",
      "0.8359598853868195\n",
      "0.8171428571428572\n",
      "{'randomforestclassifier__max_depth': 16, 'randomforestclassifier__min_samples_split': 7}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "best_estimators = []\n",
    "\n",
    "for i in range(10):\n",
    "    grid, X_test, y_test = ML_pipeline_kfold_GridSearchCV_RF_3(X,y,22*i,4)\n",
    "    print(grid.best_score_)\n",
    "    print(grid.score(X_test,y_test))\n",
    "    print(grid.best_params_)\n",
    "    best_estimators.append(grid.best_estimator_)\n",
    "    \n",
    "# save the output so I can use it later\n",
    "file = open(d + '/results/RF Models_best_estimators_ballanced_data.save', 'wb')\n",
    "pickle.dump((best_estimators),file)\n",
    "file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_pipeline_kfold_GridSearchCV_SVC(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state,stratify=y)\n",
    "    # splitter for _other\n",
    "    kf = StratifiedKFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    \n",
    "    feature_names = ['start station name', 'end station name', 'gender',\n",
    "                     'tripduration', 'Start Time','End Time']\n",
    "\n",
    "    cat_ftrs = ['start station name', 'end station name', 'gender']\n",
    "    num_ftrs = ['tripduration', 'Start Time','End Time']\n",
    "    \n",
    "    cat_ftrs_i = [df_balanced.columns.get_loc(x) for x in cat_ftrs]\n",
    "    num_ftrs_i = [df_balanced.columns.get_loc(x) for x in num_ftrs]\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(sparse=False, handle_unknown = 'ignore'))])\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "\n",
    "    # collect the transformers\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_ftrs_i),\n",
    "            ('cat', categorical_transformer, cat_ftrs_i)]) \n",
    "\n",
    "    pipe = make_pipeline(preprocessor, SVC(random_state = 22))\n",
    "    #pipe = make_pipeline(preprocess, LogisticRegression(penalty='l1', solver='saga', max_iter=10000))\n",
    "    \n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'svc__C': np.logspace(-3,4,num=8),'svc__gamma': np.logspace(-3,4,num=8)}\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(accuracy_score),\n",
    "                            cv=kf, return_train_score = True,iid=True)\n",
    "    # do kfold CV on _other\n",
    "    print(\"running\")\n",
    "    grid.fit(X_other, y_other)\n",
    "    return grid, grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "{'svc__C': 1000.0, 'svc__gamma': 0.001}\n",
      "best CV score: 0.8194842406876791\n",
      "test score: 0.8457142857142858\n",
      "running\n",
      "{'svc__C': 10000.0, 'svc__gamma': 0.001}\n",
      "best CV score: 0.8373925501432665\n",
      "test score: 0.78\n",
      "running\n",
      "{'svc__C': 10000.0, 'svc__gamma': 0.001}\n",
      "best CV score: 0.832378223495702\n",
      "test score: 0.8342857142857143\n",
      "running\n",
      "{'svc__C': 100.0, 'svc__gamma': 0.01}\n",
      "best CV score: 0.829512893982808\n",
      "test score: 0.8171428571428572\n",
      "running\n",
      "{'svc__C': 10000.0, 'svc__gamma': 0.001}\n",
      "best CV score: 0.828080229226361\n",
      "test score: 0.8314285714285714\n",
      "running\n",
      "{'svc__C': 10000.0, 'svc__gamma': 0.001}\n",
      "best CV score: 0.8237822349570201\n",
      "test score: 0.8485714285714285\n",
      "running\n",
      "{'svc__C': 100.0, 'svc__gamma': 0.01}\n",
      "best CV score: 0.8187679083094556\n",
      "test score: 0.8542857142857143\n",
      "running\n",
      "{'svc__C': 10000.0, 'svc__gamma': 0.001}\n",
      "best CV score: 0.8316618911174785\n",
      "test score: 0.8142857142857143\n",
      "running\n",
      "{'svc__C': 1000.0, 'svc__gamma': 0.001}\n",
      "best CV score: 0.832378223495702\n",
      "test score: 0.8228571428571428\n",
      "running\n",
      "{'svc__C': 100.0, 'svc__gamma': 0.01}\n",
      "best CV score: 0.830945558739255\n",
      "test score: 0.84\n",
      "test accuracy: 0.83 +/- 0.02\n"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "\n",
    "for i in range(10):\n",
    "    grid, test_score = ML_pipeline_kfold_GridSearchCV_SVC(X,y.ravel(),i*22, 5)\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "print('test accuracy:',np.around(np.mean(test_scores),2),'+/-',np.around(np.std(test_scores),2))\n",
    "\n",
    "mean_SVC_a = np.around(np.mean(test_scores),2)\n",
    "mean_SVC_sd = np.around(np.std(test_scores),2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02 1.e+03 1.e+04]\n"
     ]
    }
   ],
   "source": [
    "print(np.logspace(-3,4,num=8)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.83\n",
      "sd:  0.02\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy:\",mean_SVC_a)\n",
    "print(\"sd: \",mean_SVC_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC_score = 16.499999999999996\n"
     ]
    }
   ],
   "source": [
    "SVC_score = (mean_SVC_a - base)/mean_SVC_sd\n",
    "\n",
    "print(\"SVC_score =\",SVC_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
